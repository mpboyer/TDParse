@book{altshulerSemanticsPluralsFocus2019,
  title = {The {{Semantics}} of {{Plurals}}, {{Focus}}, {{Degrees}}, and {{Times}}: {{Essays}} in {{Honor}} of {{Roger Schwarzschild}}},
  shorttitle = {The {{Semantics}} of {{Plurals}}, {{Focus}}, {{Degrees}}, and {{Times}}},
  editor = {Altshuler, Daniel and Rett, Jessica},
  year = {2019},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-04438-1},
  urldate = {2025-03-20},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-030-04437-4 978-3-030-04438-1},
  langid = {english},
  keywords = {interface of semantics and pragmatics,ontological domains,semantics of elements,Syntax-Semantics interface,Theoretical linguistics},
  file = {/home/matthieu/Zotero/storage/B85FSQSJ/Altshuler et Rett - 2019 - The Semantics of Plurals, Focus, Degrees, and Time.pdf}
}

@book{barkerDirectCompositionality2007,
  title = {Direct {{Compositionality}}},
  author = {Barker, Chris and Jacobson, Pauline},
  year = {2007},
  publisher = {Oxford University Press, Incorporated},
  address = {Oxford, UNITED KINGDOM},
  urldate = {2025-03-24},
  abstract = {This book examines the hypothesis of "direct compositionality", which requires that semantic interpretation proceed in tandem with syntactic combination. Although associated with the dominant view in formal semantics of the 1970s and 1980s, the feasibility of direct compositionality remained unsettled, and more recently the discussion as to whether or not this view can be maintained has receded. The syntax-semantics interaction is now often seen as a process in which the syntax builds representations which, at the abstract level of logical form, are sent for interpretation to the semantics component of the language faculty. In the first extended discussion of the hypothesis of direct compositionality for twenty years, this book considers whether its abandonment might have been premature and whether in fact direct compositionality is not after all a simpler and more effective conception of the grammar than the conventional account of the syntax-semantics interface in generative grammar. It contains contributions from both sides of the debate, locates the debate in the setting of a variety of formal theories, and draws on examples from a range of languages and a range of empirical phenomena.},
  isbn = {978-0-19-152540-7},
  keywords = {Semantics},
  file = {/home/matthieu/Zotero/storage/QMTIVT7H/detail.html}
}

@article{bauerEffectSystemAlgebraic2014,
  title = {An {{Effect System}} for {{Algebraic Effects}} and {{Handlers}}},
  author = {Bauer, Andrej and Pretnar, Matija},
  year = {2014},
  month = dec,
  journal = {Logical Methods in Computer Science},
  volume = {Volume 10, Issue 4},
  publisher = {Episciences.org},
  issn = {1860-5974},
  doi = {10.2168/LMCS-10(4:9)2014},
  urldate = {2025-03-13},
  abstract = {We present an effect system for core Eff, a simplified variant of Eff, which is an ML-style programming language with first-class algebraic effects and handlers. We define an expressive effect system and prove safety of operational semantics with respect to it. Then we give a domain-theoretic denotational semantics of core Eff, using Pitts's theory of minimal invariant relations, and prove it adequate. We use this fact to develop tools for finding useful contextual equivalences, including an induction principle. To demonstrate their usefulness, we use these tools to derive the usual equations for mutable state, including a general commutativity law for computations using non-interfering references. We have formalized the effect system, the operational semantics, and the safety theorem in Twelf.},
  file = {/home/matthieu/Zotero/storage/SVATSCYV/Bauer et Pretnar - 2014 - An Effect System for Algebraic Effects and Handler.pdf}
}

@article{bonchiStringDiagramRewrite2022,
  title = {String {{Diagram Rewrite Theory I}}: {{Rewriting}} with {{Frobenius Structure}}},
  shorttitle = {String {{Diagram Rewrite Theory I}}},
  author = {Bonchi, Filippo and Gadducci, Fabio and Kissinger, Aleks and Sobocinski, Pawel and Zanasi, Fabio},
  year = {2022},
  month = apr,
  journal = {J. ACM},
  volume = {69},
  number = {2},
  pages = {1--58},
  issn = {0004-5411, 1557-735X},
  doi = {10.1145/3502719},
  urldate = {2025-03-31},
  abstract = {String diagrams are a powerful and intuitive graphical syntax, originating in theoretical physics and later formalised in the context of symmetric monoidal categories. In recent years, they have found application in the modelling of various computational structures, in fields as diverse as Computer Science, Physics, Control Theory, Linguistics, and Biology.              In several of these proposals, transformations of systems are modelled as rewrite rules of diagrams. These developments require a mathematical foundation for string diagram rewriting: whereas rewrite theory for terms is well-understood, the two-dimensional nature of string diagrams poses quite a few additional challenges.              This work systematises and expands a series of recent conference papers, laying down such a foundation. As a first step, we focus on the case of rewrite systems for string diagrammatic theories that feature a Frobenius algebra. This common structure provides a more permissive notion of composition than the usual one available in monoidal categories, and has found many applications in areas such as concurrency, quantum theory, and electrical circuits. Notably, this structure provides an exact correspondence between the syntactic notion of string diagrams modulo Frobenius structure and the combinatorial structure of hypergraphs.              Our work introduces a combinatorial interpretation of string diagram rewriting modulo Frobenius structures in terms of double-pushout hypergraph rewriting. We prove this interpretation to be sound and complete and we also show that the approach can be generalised to rewriting modulo multiple Frobenius structures. As a proof of concept, we show how to derive from these results a termination strategy for Interacting Bialgebras, an important rewrite theory in the study of quantum circuits and signal flow graphs.},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/BYGA3R9A/Bonchi et al. - 2022 - String Diagram Rewrite Theory I Rewriting with Fr.pdf}
}

@article{boyerCategoricalTypeEffecta,
  title = {On a {{Categorical Type}} and {{Effect Inference Structure}} for {{Semantic Denotation Combinations}} in {{Natural Languages}}: {{A Purely Functional Analysis}} of {{English}}},
  author = {Boyer, Matthieu},
  abstract = {The main idea is that you can consider some words to act as functors in a typing category, for example determiners: they don't change the way a word acts in a sentence, but more the setting in which the word works by adding an effect to the work. This document is based mostly on ? ] and ? ].},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/4G3A76V4/Boyer - On a Categorical Type and Effect Inference Structu.pdf}
}

@article{boyerCategoricalTypeEffectb,
  title = {On a {{Categorical Type}} and {{Effect Inference Structure}} for {{Semantic Denotation Combinations}} in {{Natural Languages}}: {{Constructing}} a {{Purely Functional Semantic Parser}} of {{English}}},
  author = {Boyer, Matthieu},
  abstract = {The main idea is that you can consider some words to act as functors in a typing category, for example determiners: they don't change the way a word acts in a sentence, but more the setting in which the word works by adding an effect to the work. The linguistics is based mostly on work by ?.},
  langid = {english},
  file = {/home/matthieu/Documents/Recherche/TDParse/report/tdparse.pdf}
}

@article{bumfordDynamicSemanticsStatic,
  title = {Dynamic Semantics with Static Types},
  author = {Bumford, Dylan and Charlow, Simon},
  abstract = {Semantic analyses of natural language typically rely on variables for the interpretation of binding relationships. This is true of standard static setups, where sentences might denote sets of variable assignments, as well as standard dynamic ones, where they might denote relations between (sets of) variable assignments. Several well-known alternative frameworks eschew object-language variables in favor of representing semantic dependencies as functional dependencies. This obviates assignments, and has the bene t that any expression's binding needs are discoverable directly from its type. But these popular variable-free approaches are limited to static, in-scope binding relationships, those in which dependents occur in the arguments of their binders. In this paper we develop a semantics that is variable-free in the same sense, but captures traditional notions of dynamic anaphora. We demonstrate the value of anaphoric type transparency with novel analyses of crossover, ellipsis, and sloppy/paycheck anaphora, and compare the new semantics, which introduces the notions of parameterized monads and lenses to the linguistics literature, with other list-based dynamic systems and other accounts of crossover.},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/7YXJDB2T/Bumford et Charlow - Dynamic semantics with static types.pdf}
}

@article{bumfordEffectdrivenInterpretation,
  title = {Effect-Driven Interpretation},
  author = {Bumford, Dylan and Charlow, Simon},
  abstract = {Computer programs are often factored into pure components---simple, total functions from inputs to outputs---and components that may have side effects---errors, changes to memory, parallel threads, abortion of the current command, etc. In this course, we make the case that human languages are similarly organized around the give and pull of pure and effectful processes, and we'll aim to show how denotational techniques from computer science can be leveraged to support elegant and illuminating semantic analyses of natural language phenomena.},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/HBBHXC72/Bumford et Charlow - DOI 10.xxxxxxxxxxxx (do not change) First publis.pdf}
}

@misc{bumfordEffectdrivenInterpretationFunctors2025,
  title = {Effect-Driven Interpretation: {{Functors}} for Natural Language Composition},
  shorttitle = {Effect-Driven Interpretation},
  author = {Bumford, Dylan and Charlow, Simon},
  year = {2025},
  month = mar,
  publisher = {LingBuzz},
  urldate = {2025-04-24},
  abstract = {Computer programs are often factored into pure components -- simple, total functions from inputs to outputs -- and components that may have side effects -- errors, changes to memory, parallel threads, abortion of the current loop, etc. We make the case that human languages are similarly organized around the give and pull of pure values and impure processes, and we'll aim to show how denotational techniques from computer science can be leveraged to support elegant and illuminating analyses of natural language composition.},
  archiveprefix = {LingBuzz},
  keywords = {composition,functors,monads,parsing,scope,semantics},
  annotation = {LingBuzz Published In: Submitted to Cambridge University Press Elements in Semantics},
  file = {/home/matthieu/Zotero/storage/SYXFB32W/Bumford et Charlow - 2025 - Effect-driven interpretation Functors for natural.pdf;/home/matthieu/Zotero/storage/T8YATP6C/008912.html}
}

@article{bumfordEffectfulCompositionNatural,
  title = {Effectful Composition in Natural Language Semantics - {{Introducing}} Functors},
  author = {Bumford, Dylan},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/F5K7W8TS/Bumford - Effectful composition in natural language semantic.pdf}
}

@inproceedings{charlowModularTheoryPronouns2017,
  title = {A Modular Theory of Pronouns and Binding},
  author = {Charlow, Simon},
  year = {2017},
  urldate = {2025-03-13},
  abstract = {. I sketch a modular treatment of pronouns using applicative functors, monads, and then applicative functors (again!). This approach dissolves theoretical issues typical of standard accounts, and extends their empirical coverage to paycheck pronouns and binding reconstruction.},
  file = {/home/matthieu/Zotero/storage/RD4C6GRQ/Charlow - 2017 - A modular theory of pronouns and binding.pdf}
}

@article{charlowSemanticsExceptionalScope,
  title = {On the Semantics of Exceptional Scope},
  author = {Charlow, Simon},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/H5PEK7QZ/Charlow - On the semantics of exceptional scope.pdf}
}

@article{clarkCompositionalDistributionalModel,
  title = {A {{Compositional Distributional Model}} of {{Meaning}}},
  author = {Clark, Stephen and Coecke, Bob and Sadrzadeh, Mehrnoosh},
  abstract = {We propose a mathematical framework for a unification of the distributional theory of meaning in terms of vector space models, and a compositional theory for grammatical types, namely Lambek's pregroup semantics. A key observation is that the monoidal category of (finite dimensional) vector spaces, linear maps and the tensor product, as well as any pregroup, are examples of compact closed categories. Since, by definition, a pregroup is a compact closed category with trivial morphisms, its compositional content is reflected within the compositional structure of any non-degenerate compact closed category. The (slightly refined) category of vector spaces enables us to compute the meaning of a compound well-typed sentence from the meaning of its constituents, by `lifting' the type reduction mechanisms of pregroup semantics to the whole category. These sentence meanings live in a single space, independent of the grammatical structure of the sentence. Hence we can use the inner-product to compare meanings of arbitrary sentences. A variation of this procedure which involves constraining the scalars of the vector spaces to the semiring of Booleans results in the well-known Montague semantics.},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/EIYW3GT6/Clark et al. - A Compositional Distributional Model of Meaning.pdf}
}

@misc{coeckeMathematicalFoundationsCompositional2010,
  title = {Mathematical {{Foundations}} for a {{Compositional Distributional Model}} of {{Meaning}}},
  author = {Coecke, Bob and Sadrzadeh, Mehrnoosh and Clark, Stephen},
  year = {2010},
  month = mar,
  number = {arXiv:1003.4394},
  eprint = {1003.4394},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1003.4394},
  urldate = {2025-03-31},
  abstract = {We propose a mathematical framework for a unification of the distributional theory of meaning in terms of vector space models, and a compositional theory for grammatical types, for which we rely on the algebra of Pregroups, introduced by Lambek. This mathematical framework enables us to compute the meaning of a well-typed sentence from the meanings of its constituents. Concretely, the type reductions of Pregroups are `lifted' to morphisms in a category, a procedure that transforms meanings of constituents into a meaning of the (well-typed) whole. Importantly, meanings of whole sentences live in a single space, independent of the grammatical structure of the sentence. Hence the inner-product can be used to compare meanings of arbitrary sentences, as it is for comparing the meanings of words in the distributional model. The mathematical structure we employ admits a purely diagrammatic calculus which exposes how the information flows between the words in a sentence in order to make up the meaning of the whole sentence. A variation of our `categorical model' which involves constraining the scalars of the vector spaces to the semiring of Booleans results in a Montague-style Boolean-valued semantics.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Logic in Computer Science,Mathematics - Category Theory},
  file = {/home/matthieu/Zotero/storage/UCP5YYW6/Coecke et al. - 2010 - Mathematical Foundations for a Compositional Distr.pdf;/home/matthieu/Zotero/storage/QJSSPC48/1003.html}
}

@misc{corbynHomotopyioProofAssistant2024,
  title = {Homotopy.Io: A Proof Assistant for Finitely-Presented Globular \$n\$-Categories},
  shorttitle = {Homotopy.Io},
  author = {Corbyn, Nathan and Heidemann, Lukas and Hu, Nick and Sarti, Chiara and Tataru, Calin and Vicary, Jamie},
  year = {2024},
  month = feb,
  number = {arXiv:2402.13179},
  eprint = {2402.13179},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.13179},
  urldate = {2025-03-31},
  abstract = {We present the proof assistant homotopy.io for working with finitely-presented semistrict higher categories. The tool runs in the browser with a point-and-click interface, allowing direct manipulation of proof objects via a graphical representation. We describe the user interface and explain how the tool can be used in practice. We also describe the essential subsystems of the tool, including collapse, contraction, expansion, typechecking, and layout, as well as key implementation details including data structure encoding, memoisation, and rendering. These technical innovations have been essential for achieving good performance in a resource-constrained setting.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Logic in Computer Science,Mathematics - Category Theory},
  file = {/home/matthieu/Zotero/storage/KNIIKDBN/Corbyn et al. - 2024 - homotopy.io a proof assistant for finitely-presen.pdf;/home/matthieu/Zotero/storage/GQJTV8L8/2402.html}
}

@article{delpeuchAutonomizationMonoidalCategories2020,
  title = {Autonomization of {{Monoidal Categories}}},
  author = {Delpeuch, Antonin},
  year = {2020},
  month = sep,
  journal = {Electron. Proc. Theor. Comput. Sci.},
  volume = {323},
  eprint = {1411.3827},
  primaryclass = {math},
  pages = {24--43},
  issn = {2075-2180},
  doi = {10.4204/EPTCS.323.3},
  urldate = {2025-04-07},
  abstract = {We show that contrary to common belief in the DisCoCat community, a monoidal category is all that is needed to define a categorical compositional model of natural language. This relies on a construction which freely adds adjoints to a monoidal category. In the case of distributional semantics, this broadens the range of available models, to include non-linear maps and cartesian products for instance. We illustrate the applications of this principle to various distributional models of meaning.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Mathematics - Category Theory},
  file = {/home/matthieu/Zotero/storage/G88QY9MY/Delpeuch - 2020 - Autonomization of Monoidal Categories.pdf;/home/matthieu/Zotero/storage/WBF7VIUW/1411.html}
}

@misc{delpeuchNormalizationPlanarString2022,
  title = {Normalization for Planar String Diagrams and a Quadratic Equivalence Algorithm},
  author = {Delpeuch, Antonin and Vicary, Jamie},
  year = {2022},
  month = jan,
  number = {arXiv:1804.07832},
  eprint = {1804.07832},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1804.07832},
  urldate = {2025-03-31},
  abstract = {In the graphical calculus of planar string diagrams, equality is generated by exchange moves, which swap the heights of adjacent vertices. We show that left- and right-handed exchanges each give strongly normalizing rewrite strategies for connected string diagrams. We use this result to give a linear-time solution to the equivalence problem in the connected case, and a quadratic solution in the general case. We also give a stronger proof of the Joyal-Street coherence theorem, settling Selinger's conjecture on recumbent isotopy.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Logic in Computer Science},
  file = {/home/matthieu/Zotero/storage/2BAR2SFT/Delpeuch et Vicary - 2022 - Normalization for planar string diagrams and a qua.pdf}
}

@book{dixonSemanticApproachEnglish2005,
  title = {A {{Semantic Approach}} to {{English Grammar}}},
  author = {Dixon, R. M. W.},
  year = {2005},
  publisher = {Oxford University Press, Incorporated},
  address = {Oxford, UNITED KINGDOM},
  urldate = {2025-03-19},
  abstract = {This book shows how grammar helps people communicate and looks at the ways grammar and meaning interrelate. The author starts from the notion that a speaker codes a meaning into grammatical forms which the listener is then able to recover: each word, he shows, has its own meaning and each bit of grammar its own function, their combinations creating and limiting the possibilities for different words. He uncovers a rationale for the varying grammatical properties of different words. and in the process explains many facts about English - such as why we can say I wish to go, I wish that he would go, and I want to go but not I want that he would go. -;This book shows how grammar helps people communicate and looks at the ways grammar and meaning interrelate. The author starts from the notion that a speaker codes a meaning into grammatical forms which the listener is then able to recover: each word, he shows, has its own meaning and each bit of grammar its own function, their combinations creating and limiting the possibilities for different words. He uncovers a rationale for the varying grammatical properties of different words. and in the process explains many facts about English - such as why we can say I wish to go, I wish that he would go, and I want to go but not I want that he would go. The first part of the book reviews the main points of English syntax and discusses English verbs in terms of their semantic types including those of Motion, Giving, Speaking, Liking, and Trying. In the second part Professor Dixon looks at eight grammatical topics, including complement clauses, transitivity and causatives, passives, and the promotion of a non-subject to subject, as in Dictionaries sell well. This is the updated and revised edition of A New Approach to English Grammar on Semantic Principles. It includes new chapters on tense and aspect, nominalizations and possession, and adverbs and negation, and contains a new discussion of comparative forms of adjectives. It also explains recent changes in English grammar, including how they has replaced the tabooed he as a pronoun referring to either gender, as in When a student reads this book, they will learn a. lot about English grammar in a most enjoyable manner. -},
  isbn = {978-0-19-153004-3},
  keywords = {English language -- Grammar.,English language -- Semantics.},
  file = {/home/matthieu/Zotero/storage/M5N528UL/Dixon - 2005 - A Semantic Approach to English Grammar.pdf;/home/matthieu/Zotero/storage/4XGVJ4XQ/detail.html}
}

@misc{feliceCategoricalToolsNatural2022,
  title = {Categorical {{Tools}} for {{Natural Language Processing}}},
  author = {de Felice, Giovanni},
  year = {2022},
  month = dec,
  number = {arXiv:2212.06636},
  eprint = {2212.06636},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2212.06636},
  urldate = {2025-04-07},
  abstract = {This thesis develops the translation between category theory and computational linguistics as a foundation for natural language processing. The three chapters deal with syntax, semantics and pragmatics. First, string diagrams provide a unified model of syntactic structures in formal grammars. Second, functors compute semantics by turning diagrams into logical, tensor, neural or quantum computation. Third, the resulting functorial models can be composed to form games where equilibria are the solutions of language processing tasks. This framework is implemented as part of DisCoPy, the Python library for computing with string diagrams. We describe the correspondence between categorical, linguistic and computational structures, and demonstrate their applications in compositional natural language processing.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Mathematics - Category Theory},
  file = {/home/matthieu/Zotero/storage/LW3JD3B9/Felice - 2022 - Categorical Tools for Natural Language Processing.pdf;/home/matthieu/Zotero/storage/NN66W7BQ/2212.html}
}

@article{feliceDisCoPyMonoidalCategories2021,
  title = {{{DisCoPy}}: {{Monoidal Categories}} in {{Python}}},
  shorttitle = {{{DisCoPy}}},
  author = {de Felice, Giovanni and Toumi, Alexis and Coecke, Bob},
  year = {2021},
  month = feb,
  journal = {Electron. Proc. Theor. Comput. Sci.},
  volume = {333},
  eprint = {2005.02975},
  primaryclass = {math},
  pages = {183--197},
  issn = {2075-2180},
  doi = {10.4204/EPTCS.333.13},
  urldate = {2025-04-04},
  abstract = {We introduce DisCoPy, an open source toolbox for computing with monoidal categories. The library provides an intuitive syntax for defining string diagrams and monoidal functors. Its modularity allows the efficient implementation of computational experiments in the various applications of category theory where diagrams have become a lingua franca. As an example, we used DisCoPy to perform natural language processing on quantum hardware for the first time.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Category Theory},
  file = {/home/matthieu/Zotero/storage/VLP89LHA/Felice et al. - 2021 - DisCoPy Monoidal Categories in Python.pdf;/home/matthieu/Zotero/storage/DLFEGW9Q/2005.html}
}

@book{geeraertsTheoriesLexicalSemantics2010,
  title = {Theories of Lexical Semantics},
  author = {Geeraerts, Dirk},
  year = {2010},
  publisher = {Oxford University Press},
  address = {Oxford},
  isbn = {978-0-19-170628-8},
  keywords = {Linguistic change,Semantics Historical},
  file = {/home/matthieu/Zotero/storage/28HCNCED/12552561.html}
}

@misc{goodaleManifoldsConceptualRepresentations2022,
  title = {Manifolds as Conceptual Representations in Formal Semantics},
  author = {Goodale, Michael},
  year = {2022},
  month = jun,
  publisher = {LingBuzz},
  urldate = {2025-04-16},
  abstract = {I lay the foundation of a formal theory of concepts and a formal language to manipulate concepts compositionally, unifying insights from linguistics, philosophy, psychology, and artificial intelligence. The approach can be used in a formal semantic framework and defines concepts as mathematical objects that incorporates both extension-determining sets along with notions of similarity and typicality which have long been argued to be central to concepts. Under this view, concepts are tripartite: each concept consists of a manifold, a probability distribution over the points of the manifold, and a metric tensor to determine distances along the manifold. The manifold determines the extension of a concept over a vector space of all conceivable objects. The metric tensor quantifies the distance between objects along the manifold. This allows us to determine how similar objects are to one another qua a given concept. Finally, the probability distribution serves to define the typicality of a given object within a concept. I apply this preliminary model to generic statements, privative modification, Frege's puzzle and certain reasoning tasks, showing its promise in providing accounts of diverse and recalcitrant puzzles in semantics. Finally, a computational implementation of the model using a neurosymbolic approach with invertible neural networks is described.},
  archiveprefix = {LingBuzz},
  keywords = {concepts,generics,lexical semantics,manifolds,neurosymbolic,privative adjectives,reasoning,semantics},
  annotation = {LingBuzz Published In: Master's thesis, Ecole normale sup{\'e}rieure},
  file = {/home/matthieu/Zotero/storage/YYY2N95P/Goodale - 2022 - Manifolds as conceptual representations in formal .pdf;/home/matthieu/Zotero/storage/SQHW7XP7/006797.html}
}

@misc{grodinPolymorphicEffectHandlers2024,
  title = {Poly-Morphic Effect Handlers},
  author = {Grodin, Harrison and Spivak, David},
  year = {2024},
  month = jan,
  journal = {Topos Institute},
  urldate = {2025-03-27},
  abstract = {In computer science, programmers often perform effects to interact with the surrounding environment. For example, a program may print strings or interact with mutable state. Then, effects may be handled, implemented in terms of other effects. In this post, we reconstruct a categorical semantics for programs with effects, and we isolate a class of composable effect handlers that may be concisely described in the language of polynomial functors, the free monad monad, and the Grothendieck construction.},
  howpublished = {https://topos.institute/blog/2024-01-03-algebraic-effect-handlers/},
  langid = {english}
}

@misc{groveProbabilisticCompositionalSemantics2023,
  title = {Probabilistic Compositional Semantics, Purely},
  author = {Grove, Julian and Bernardy, Jean-Philippe},
  year = {2023},
  month = jul,
  publisher = {LingBuzz},
  urldate = {2025-04-21},
  abstract = {We provide a general framework for the integration of formal semantics with probabilistic reasoning. This framework is conservative, in the sense that it relies only on typed {$\lambda$}-calculus and is thus compatible with logical systems already in use. The framework is also presented modularly, in that it regards probabilistic effects (i.e., sampling and marginalization) as /side effects/, using continuations. We show how our framework may be used to build probabilistic programs compositionally within typed {$\lambda$}-calculus and then illustrate its use on two applications: semantic learning and pragmatic inference within the Rational Speech Act framework.},
  archiveprefix = {LingBuzz},
  keywords = {bayesian semantics,compositional semantics,continuations,monads,probabilities,rational speech act,semantics},
  annotation = {LingBuzz Published In: In proceedings of JSAI-isAI 2021/LENLS18},
  file = {/home/matthieu/Zotero/storage/DIZH6BD2/Grove et Bernardy - 2023 - Probabilistic compositional semantics, purely.pdf;/home/matthieu/Zotero/storage/58FCJBCE/006284.html}
}

@book{heimSemanticsGenerativeGrammar1998,
  title = {Semantics in Generative Grammar},
  author = {Heim, Irene and Kratzer, Angelika},
  year = {1998},
  series = {Blackwell Textbooks in Linguistics},
  number = {13},
  publisher = {Blackwell},
  address = {Malden, MA},
  isbn = {978-0-631-19712-6 978-0-631-19713-3},
  langid = {english},
  lccn = {P325.5.G45 H45 1998},
  keywords = {Generative grammar,Semantics},
  file = {/home/matthieu/Zotero/storage/LUU4QX72/Heim et Kratzer - 1998 - Semantics in generative grammar.pdf}
}

@inproceedings{heppleParsingDerivationalEquivalence1989,
  title = {Parsing and Derivational Equivalence},
  booktitle = {Proceedings of the Fourth Conference on {{European}} Chapter of the {{Association}} for {{Computational Linguistics}}  -},
  author = {Hepple, Mark and Morrill, Glyn},
  year = {1989},
  pages = {10--18},
  publisher = {Association for Computational Linguistics},
  address = {Manchester, England},
  doi = {10.3115/976815.976817},
  urldate = {2025-04-28},
  abstract = {It is a tacit assumption of m u c h linguistic inquiry that alldistinctderivations of a string should assign distinct meanings. But despite the tidiness of such derivational uniqueness, there seems to be no a priori reason to assume that a g r a m m a r must have this property. Ifa grammar exhibits derivational equivalence, whereby distinct derivations of a string assign the same meanings, naive exhaustive search for all derivations will be redundant, and quite possibly intractable. In this paper we show how notions of derivation-reduction and normal form can be used to avoid unnecessary work while parsing with grammars exhibiting derivational equivalence. With grammar regarded as analogous to logic, derivations are proofs; what we are advocating is proof-reduction, and normal form proof; the invocation of these logicaltechniques adds a further paragraph to the story of parsing-as-deduction.},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/QWT3JNYF/Hepple et Morrill - 1989 - Parsing and derivational equivalence.pdf}
}

@book{hinzeIntroducingStringDiagrams2023,
  title = {Introducing {{String Diagrams}}: {{The Art}} of {{Category Theory}}},
  shorttitle = {Introducing {{String Diagrams}}},
  author = {Hinze, Ralf and Marsden, Dan},
  year = {2023},
  month = jul,
  edition = {1},
  publisher = {Cambridge University Press},
  doi = {10.1017/9781009317825},
  urldate = {2025-03-28},
  abstract = {String diagrams are powerful graphical methods for reasoning in elementary category theory. Written in an informal expository style, this book provides a self-contained introduction to these diagrammatic techniques, ideal for graduate students and researchers. Much of the book is devoted to worked examples highlighting how best to use string diagrams to solve realistic problems in elementary category theory. A range of topics are explored from the perspective of string diagrams, including adjunctions, monad and comonads, Kleisli and Eilenberg--Moore categories, and endofunctor algebras and coalgebras. Careful attention is paid throughout to exploit the freedom of the graphical notation to draw diagrams that aid understanding and subsequent calculations. Each chapter contains plentiful exercises of varying levels of difficulty, suitable for self-study or for use by instructors.},
  copyright = {https://www.cambridge.org/core/terms},
  isbn = {978-1-00-931782-5 978-1-00-931786-3},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/K5MZ5FK4/Hinze et Marsden - 2023 - Introducing String Diagrams The Art of Category T.pdf;/home/matthieu/Zotero/storage/DG7U9WEX/36F8F1BCA0C61522283C2FED620EBC0D.html}
}

@article{joyalGeometryTensorCalculus1991,
  title = {The Geometry of Tensor Calculus, {{I}}},
  author = {Joyal, Andr{\'e} and Street, Ross},
  year = {1991},
  month = jul,
  journal = {Advances in Mathematics},
  volume = {88},
  number = {1},
  pages = {55--112},
  issn = {00018708},
  doi = {10.1016/0001-8708(91)90003-P},
  urldate = {2025-03-28},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/FQWAM6RF/Joyal et Street - 1991 - The geometry of tensor calculus, I.pdf}
}

@incollection{kissingerQuantomaticProofAssistant2015,
  title = {Quantomatic: {{A Proof Assistant}} for {{Diagrammatic Reasoning}}},
  shorttitle = {Quantomatic},
  author = {Kissinger, Aleks and Zamdzhiev, Vladimir},
  year = {2015},
  volume = {9195},
  eprint = {1503.01034},
  primaryclass = {cs},
  pages = {326--336},
  doi = {10.1007/978-3-319-21401-6_22},
  urldate = {2025-03-31},
  abstract = {Monoidal algebraic structures consist of operations that can have multiple outputs as well as multiple inputs, which have applications in many areas including categorical algebra, programming language semantics, representation theory, algebraic quantum information, and quantum groups. String diagrams provide a convenient graphical syntax for reasoning formally about such structures, while avoiding many of the technical challenges of a term-based approach. Quantomatic is a tool that supports the (semi-)automatic construction of equational proofs using string diagrams. We briefly outline the theoretical basis of Quantomatic's rewriting engine, then give an overview of the core features and architecture and give a simple example project that computes normal forms for commutative bialgebras.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Logic in Computer Science,Computer Science - Mathematical Software,Mathematics - Category Theory},
  file = {/home/matthieu/Zotero/storage/HCWWSAIV/Kissinger et Zamdzhiev - 2015 - Quantomatic A Proof Assistant for Diagrammatic Re.pdf;/home/matthieu/Zotero/storage/43AYDGQV/1503.html}
}

@article{kleinTypeDrivenTranslation1985,
  title = {Type-{{Driven Translation}}},
  author = {Klein, Ewan and Sag, Ivan A.},
  year = {1985},
  journal = {Linguistics and Philosophy},
  volume = {8},
  number = {2},
  pages = {163--201},
  publisher = {Springer},
  doi = {10.1007/bf00632365}
}

@article{lambekMATHEMATICSSENTENCESTRUCTURE,
  title = {{{THE MATHEMATICS OF SENTENCE STRUCTURE}}},
  author = {Lambek, Joachim},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/KX4WNBIG/Lambek - THE MATHEMATICS OF SENTENCE STRUCTURE.pdf}
}

@article{lambekTypeGrammarsPregroups2001,
  title = {Type {{Grammars}} as {{Pregroups}}},
  author = {Lambek, Joachim},
  year = {2001},
  month = apr,
  journal = {Grammars},
  volume = {4},
  number = {1},
  pages = {21--39},
  issn = {1572-848X},
  doi = {10.1023/A:1011444711686},
  urldate = {2025-04-07},
  langid = {english},
  keywords = {Artificial Intelligence,Computational Linguistic,Mathematical Logic,Theoretical Language,Type Grammar},
  file = {/home/matthieu/Zotero/storage/ZZS6FBYU/Lambek - 2001 - Type Grammars as Pregroups.pdf}
}

@article{lengrandNormalisationEquivalenceProof,
  title = {Normalisation \& {{Equivalence}} in {{Proof Theory}} \& {{Type Theory}}},
  author = {Lengrand, St{\'e}phane},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/RXV276Q5/Lengrand - Normalisation & Equivalence in Proof Theory & Type.pdf}
}

@misc{marsdenCategoryTheoryUsing2014,
  title = {Category {{Theory Using String Diagrams}}},
  author = {Marsden, Daniel},
  year = {2014},
  month = nov,
  number = {arXiv:1401.7220},
  eprint = {1401.7220},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1401.7220},
  urldate = {2025-03-27},
  abstract = {In work of Fokkinga and Meertens a calculational approach to category theory is developed. The scheme has many merits, but sacrifices useful type information in the move to an equational style of reasoning. By contrast, traditional proofs by diagram pasting retain the vital type information, but poorly express the reasoning and development of categorical proofs. In order to combine the strengths of these two perspectives, we propose the use of string diagrams, common folklore in the category theory community, allowing us to retain the type information whilst pursuing a calculational form of proof. These graphical representations provide a topological perspective on categorical proofs, and silently handle functoriality and naturality conditions that require awkward bookkeeping in more traditional notation. Our approach is to proceed primarily by example, systematically applying graphical techniques to many aspects of category theory. We develop string diagrammatic formulations of many common notions, including adjunctions, monads, Kan extensions, limits and colimits. We describe representable functors graphically, and exploit these as a uniform source of graphical calculation rules for many category theoretic concepts. These graphical tools are then used to explicitly prove many standard results in our proposed diagrammatic style.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Logic in Computer Science,Mathematics - Category Theory},
  file = {/home/matthieu/Zotero/storage/M7R4EK4V/Marsden - 2014 - Category Theory Using String Diagrams.pdf;/home/matthieu/Zotero/storage/9U3DRNRK/1401.html}
}

@article{marsikAlgebraicEffectsHandlers,
  title = {Algebraic {{Effects}} and {{Handlers}} in {{Natural Language Interpretation}}},
  author = {Mar{\v s}{\'i}k, Ji{\v r}{\'i} and Amblard, Maxime},
  abstract = {Phenomena on the syntax-semantics interface of natural languages have been observed to have links with programming language semantics, namely computational effects and evaluation order. We explore this connection to be able to profit from recent development in the study of effects. We propose adopting algebraic effects and handlers as tools for facilitating a uniform and integrated treatment of different non-compositional phenomena on the syntax-semantics interface.},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/HN2B2R2Q/Maršík et Amblard - Algebraic Effects and Handlers in Natural Language.pdf}
}

@inproceedings{melliesFunctorsAreType2015,
  title = {Functors Are {{Type Refinement Systems}}},
  booktitle = {Proceedings of the 42nd {{Annual ACM SIGPLAN-SIGACT Symposium}} on {{Principles}} of {{Programming Languages}}},
  author = {Melli{\`e}s, Paul-Andr{\'e} and Zeilberger, Noam},
  year = {2015},
  month = jan,
  pages = {3--16},
  publisher = {ACM},
  address = {Mumbai India},
  doi = {10.1145/2676726.2676970},
  urldate = {2025-03-04},
  abstract = {The standard reading of type theory through the lens of category theory is based on the idea of viewing a type system as a category of well-typed terms. We propose a basic revision of this reading: rather than interpreting type systems as categories, we describe them as functors from a category of typing derivations to a category of underlying terms. Then, turning this around, we explain how in fact any functor gives rise to a generalized type system, with an abstract notion of typing judgment, typing derivations and typing rules. This leads to a purely categorical reformulation of various natural classes of type systems as natural classes of functors.},
  isbn = {978-1-4503-3300-9},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/ENC3CS3B/Melliès et Zeilberger - 2015 - Functors are Type Refinement Systems.pdf}
}

@inproceedings{melliesGameSemanticsString2012,
  title = {Game {{Semantics}} in {{String Diagrams}}},
  booktitle = {2012 27th {{Annual IEEE Symposium}} on {{Logic}} in {{Computer Science}}},
  author = {Melli{\`e}s, Paul-Andr{\'e}},
  year = {2012},
  month = jun,
  pages = {481--490},
  issn = {1043-6871},
  doi = {10.1109/LICS.2012.58},
  urldate = {2025-03-31},
  abstract = {A dialogue category is a symmetric monoidal category equipped with a notion of tensorial negation. We establish that the free dialogue category is a category of dialogue games and total innocent strategies. The connection clarifies the algebraic and logical nature of dialogue games, and their intrinsic connection to linear continuations. The proof of the statement is based on an algebraic presentation of dialogue categories inspired by knot theory, and a factorization theorem established by rewriting techniques.},
  keywords = {2-dimensional algebra,Coherence,coherence theorems,Dialogue games,Games,Generators,innocent strategies,linear continuations,ribbon categories,Semantics,string diagrams,Syntactics,Tensile stress,Vectors},
  file = {/home/matthieu/Zotero/storage/B2ZDYDI4/Melliès - 2012 - Game Semantics in String Diagrams.pdf;/home/matthieu/Zotero/storage/AFYV8X44/6280467.html}
}

@article{melliesLambdaCalculCategories,
  title = {{Lambda-Calcul et Cat{\'e}gories}},
  author = {Mellies, Paul-Andr{\'e}},
  langid = {french},
  file = {/home/matthieu/Documents/ETUDES/ENS/M1/S1/Info/Mellies/cours.pdf}
}

@inproceedings{moggiComputationalLambdacalculusMonads1989,
  title = {Computational Lambda-Calculus and Monads},
  booktitle = {[1989] {{Proceedings}}. {{Fourth Annual Symposium}} on {{Logic}} in {{Computer Science}}},
  author = {Moggi, E.},
  year = {1989},
  pages = {14--23},
  publisher = {IEEE Comput. Soc. Press},
  address = {Pacific Grove, CA, USA},
  doi = {10.1109/LICS.1989.39155},
  urldate = {2025-03-07},
  abstract = {The {$\lambda$}-calculus is considered an useful mathematical tool in the study of programming languages, since programs can be identified with {$\lambda$}-terms. However, if one goes further and uses {$\beta\eta$}-conversion to prove equivalence of programs, then a gross simplification1 is introduced, that may jeopardise the applicability of theoretical results to real situations. In this paper we introduce a new calculus based on a categorical semantics for computations. This calculus provides a correct basis for proving equivalence of programs, independent from any specific computational model.},
  isbn = {978-0-8186-1954-0},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/XGQYMUFX/Moggi - 1989 - Computational lambda-calculus and monads.pdf}
}

@article{moggiNotionsComputationMonads1991,
  title = {Notions of Computation and Monads},
  author = {Moggi, Eugenio},
  year = {1991},
  month = jul,
  journal = {Information and Computation},
  series = {Selections from 1989 {{IEEE Symposium}} on {{Logic}} in {{Computer Science}}},
  volume = {93},
  number = {1},
  pages = {55--92},
  issn = {0890-5401},
  doi = {10.1016/0890-5401(91)90052-4},
  urldate = {2025-03-27},
  abstract = {The {$\lambda$}-calculus is considered a useful mathematical tool in the study of programming languages, since programs can be identified with {$\lambda$}-terms. However, if one goes further and uses {$\beta\eta$}-conversion to prove equivalence of programs, then a gross simplification is introduced (programs are identified with total functions from values to values) that may jeopardise the applicability of theoretical results. In this paper we introduce calculi, based on a categorical semantics for computations, that provide a correct basis for proving equivalence of programs for a wide range of notions of computation.},
  file = {/home/matthieu/Zotero/storage/4SZ4JAH5/0890540191900524.html}
}

@misc{MonadsEffects,
  title = {Monads and {{Effects}}},
  journal = {ResearchGate},
  urldate = {2025-03-13},
  abstract = {Access 135+ million publications and connect with 20+ million researchers. Join for free and gain visibility by uploading your research.},
  howpublished = {https://www.researchgate.net/publication/2806790\_Monads\_and\_Effects},
  langid = {english}
}

@article{mootSecondOrderLambda2011,
  title = {Second Order Lambda Calculus for Meaning Assembly: On the Logical Syntax of Plurals},
  shorttitle = {Second Order Lambda Calculus for Meaning Assembly},
  author = {Moot, Richard},
  year = {2011},
  month = jan,
  urldate = {2025-03-20},
  abstract = {Overview In order to model a number of phenomena of lexical pragmatics in a compositional framework, several contributions developed in our team [1, 4, 6, 5] have used the system F of Jean-Yves Girard (1971)[2, 3] to compose logical formulae},
  file = {/home/matthieu/Zotero/storage/JKFAA3HV/Second_order_lambda_calculus_for_meaning.pdf;/home/matthieu/Zotero/storage/K7N34WTW/Second_order_lambda_calculus_for_meaning_assembly_on_the_logical_syntax_of_plurals.html}
}

@misc{nakahiraDiagrammaticCategoryTheory2024,
  title = {Diagrammatic Category Theory},
  author = {Nakahira, Kenji},
  year = {2024},
  month = jul,
  number = {arXiv:2307.08891},
  eprint = {2307.08891},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.08891},
  urldate = {2025-03-27},
  abstract = {In category theory, the use of string diagrams is well known to aid in the intuitive understanding of certain concepts, particularly when dealing with adjunctions and monoidal categories. We show that string diagrams are also useful in exploring fundamental properties of basic concepts in category theory, such as universal properties, (co)limits, Kan extensions, and (co)ends. For instance, string diagrams are utilized to represent visually intuitive proofs of the Yoneda lemma, necessary and sufficient conditions for being adjunctions, the fact that right adjoints preserve limits (RAPL), and necessary and sufficient conditions for having pointwise Kan extensions. We also introduce a method for intuitively calculating (co)ends using diagrammatic representations and employ it to prove several properties of (co)ends and weighted (co)limits. This paper proposes that using string diagrams is an effective approach for beginners in category theory to learn the fundamentals of the subject in an intuitive and understandable way.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Category Theory},
  file = {/home/matthieu/Zotero/storage/8N2HN3K2/Nakahira - 2024 - Diagrammatic category theory.pdf;/home/matthieu/Zotero/storage/UQF8LSZR/2307.html}
}

@inproceedings{nielsonTypeEffectSystems1999,
  title = {Type and {{Effect Systems}}},
  booktitle = {Correct {{System Design}}},
  author = {Nielson, Flemming and Nielson, Hanne Riis},
  editor = {Goos, Gerhard and Hartmanis, Juris and Van Leeuwen, Jan and Olderog, Ernst-R{\"u}diger and Steffen, Bernhard},
  year = {1999},
  volume = {1710},
  pages = {114--136},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-48092-7_6},
  urldate = {2025-03-05},
  abstract = {The design and implementation of a correct system can benefit from employing static techniques for ensuring that the dynamic behaviour satisfies the specification. Many programming languages incorporate types for ensuring that certain operations are only applied to data of the appropriate form. A natural extension of type checking techniques is to enrich the types with annotations and effects that further describe intensional aspects of the dynamic behaviour.},
  isbn = {978-3-540-66624-0 978-3-540-48092-1},
  file = {/home/matthieu/Zotero/storage/FYMLVTAC/nielson-nielson-csd99.pdf}
}

@misc{OCamlLanguageExtensions,
  title = {{{OCaml}} - {{Language}} Extensions},
  urldate = {2025-03-13},
  howpublished = {https://ocaml.org/manual/5.3/effects.html\#s\%3Aeffects-shallow}
}

@article{parteeLecture2Lambda,
  title = {Lecture 2. {{Lambda}} Abstraction, {{NP}} Semantics, and a {{Fragment}} of {{English}}},
  author = {Partee, B},
  journal = {Formal Semantics},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/BLXAQ26Q/Partee - Lecture 2. Lambda abstraction, NP semantics, and a.pdf}
}

@article{pietersGeneralizedMonoidalEffects2020,
  title = {Generalized Monoidal Effects and Handlers},
  author = {Pieters, Ruben P. and Rivas, Exequiel and Schrijvers, Tom},
  year = {2020},
  month = jan,
  journal = {Journal of Functional Programming},
  volume = {30},
  pages = {e23},
  issn = {0956-7968, 1469-7653},
  doi = {10.1017/S0956796820000106},
  urldate = {2025-03-27},
  abstract = {Algebraic effects and handlers are a convenient method for structuring monadic effects with primitive effectful operations and separating the syntax from the interpretation of these operations. However, the scope of conventional handlers is limited as not all side effects are monadic in nature. This paper generalizes the notion of algebraic effects and handlers from monads to generalized monoids, which notably covers applicative functors and arrows as well as monads. For this purpose, we switch the category theoretical basis from free algebras to free monoids. In addition, we show how lax monoidal functors enable the reuse of handlers and programs across different computation classes, for example, handling applicative computations with monadic handlers. We motivate and present these handler interfaces in the context of build systems. Tasks in a build system are represented by a free computation and their interpretation as a handler. This use case is based on the work of Mokhov et al. [(2018). PACMPL2(ICFP), 79:1--79:29.].},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/AIB8FBZ5/Pieters et al. - 2020 - Generalized monoidal effects and handlers.pdf}
}

@inproceedings{plotkinComputationalEffectsOperations2004,
  title = {Computational Effects and Operations: An Overview},
  shorttitle = {Computational Effects and Operations},
  booktitle = {Electronic {{Notes}} in {{Theoretical Computer Science}}},
  author = {Plotkin, Gordon and Power, A. J.},
  year = {2004},
  volume = {73},
  pages = {149--163},
  publisher = {Elsevier},
  issn = {1571-0661},
  doi = {10.1016/j.entcs.2004.08.008},
  urldate = {2025-03-17},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/RTDDN4P5/Plotkin et Power - 2004 - Computational effects and operations an overview.pdf}
}

@article{plotkinHandlingAlgebraicEffects2013,
  title = {Handling {{Algebraic Effects}}},
  author = {Plotkin, Gordon D. and Pretnar, Matija},
  year = {2013},
  month = dec,
  journal = {Logical Methods in Computer Science},
  volume = {Volume 9, Issue 4},
  publisher = {Episciences.org},
  issn = {1860-5974},
  doi = {10.2168/LMCS-9(4:23)2013},
  urldate = {2025-03-13},
  abstract = {Algebraic effects are computational effects that can be represented by an equational theory whose operations produce the effects at hand. The free model of this theory induces the expected computational monad for the corresponding effect. Algebraic effects include exceptions, state, nondeterminism, interactive input/output, and time, and their combinations. Exception handling, however, has so far received no algebraic treatment. We present such a treatment, in which each handler yields a model of the theory for exceptions, and each handling construct yields the homomorphism induced by the universal property of the free model. We further generalise exception handlers to arbitrary algebraic effects. The resulting programming construct includes many previously unrelated examples from both theory and practice, including relabelling and restriction in Milner's CCS, timeout, rollback, and stream redirection.},
  file = {/home/matthieu/Zotero/storage/UA7JWGDC/Plotkin et Pretnar - 2013 - Handling Algebraic Effects.pdf}
}

@article{pretnarIntroductionAlgebraicEffects2015,
  title = {An {{Introduction}} to {{Algebraic Effects}} and {{Handlers}}. {{Invited}} Tutorial Paper},
  author = {Pretnar, Matija},
  year = {2015},
  month = dec,
  journal = {Electronic Notes in Theoretical Computer Science},
  volume = {319},
  pages = {19--35},
  issn = {15710661},
  doi = {10.1016/j.entcs.2015.12.003},
  urldate = {2025-03-13},
  abstract = {This paper is a tutorial on algebraic effects and handlers. In it, we explain what algebraic effects are, give ample examples to explain how handlers work, define an operational semantics and a type \& effect system, show how one can reason about effects, and give pointers for further reading.},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/76T2XML2/Pretnar - 2015 - An Introduction to Algebraic Effects and Handlers..pdf}
}

@article{reynoldsMeaningTypesIntrinsic2000,
  title = {The {{Meaning}} of {{Types From Intrinsic}} to {{Extrinsic Semantics}}},
  author = {Reynolds, John C.},
  year = {2000},
  month = jun,
  journal = {BRICS Report Series},
  number = {32},
  issn = {1601-5355},
  doi = {10.7146/brics.v7i32.20167},
  urldate = {2025-03-14},
  abstract = {A definition of a typed language is said to be "intrinsic" if it assignsmeanings to typings rather than arbitrary phrases, so that ill-typedphrases are meaningless. In contrast, a definition is said to be "extrinsic"if all phrases have meanings that are independent of their typings,while typings represent properties of these meanings.For a simply typed lambda calculus, extended with recursion, subtypes,and named products, we give an intrinsic denotational semanticsand a denotational semantics of the underlying untyped language. Wethen establish a logical relations theorem between these two semantics,and show that the logical relations can be "bracketed" by retractionsbetween the domains of the two semantics. From these results, wederive an extrinsic semantics that uses partial equivalence relations.},
  copyright = {Copyright (c) 2015 BRICS Report Series},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/ER8MVWGU/Reynolds - 2000 - The Meaning of Types From Intrinsic to Extrinsic S.pdf}
}

@misc{sadrzadehStaticDynamicVector2018,
  title = {Static and {{Dynamic Vector Semantics}} for {{Lambda Calculus Models}} of {{Natural Language}}},
  author = {Sadrzadeh, Mehrnoosh and Muskens, Reinhard},
  year = {2018},
  month = oct,
  number = {arXiv:1810.11351},
  eprint = {1810.11351},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1810.11351},
  urldate = {2025-04-21},
  abstract = {Vector models of language are based on the contextual aspects of language, the distributions of words and how they co-occur in text. Truth conditional models focus on the logical aspects of language, compositional properties of words and how they compose to form sentences. In the truth conditional approach, the denotation of a sentence determines its truth conditions, which can be taken to be a truth value, a set of possible worlds, a context change potential, or similar. In the vector models, the degree of co-occurrence of words in context determines how similar the meanings of words are. In this paper, we put these two models together and develop a vector semantics for language based on the simply typed lambda calculus models of natural language. We provide two types of vector semantics: a static one that uses techniques familiar from the truth conditional tradition and a dynamic one based on a form of dynamic interpretation inspired by Heim's context change potentials. We show how the dynamic model can be applied to entailment between a corpus and a sentence and provide examples.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/home/matthieu/Zotero/storage/LW6UB2JC/Sadrzadeh et Muskens - 2018 - Static and Dynamic Vector Semantics for Lambda Cal.pdf}
}

@article{schmittPluralitiesCategoriesPlural2019,
  title = {Pluralities across Categories and Plural Projection},
  author = {Schmitt, Viola},
  year = {2019},
  month = nov,
  journal = {Semantics and Pragmatics},
  volume = {12},
  pages = {17:1-55},
  issn = {1937-8912},
  doi = {10.3765/sp.12.17},
  urldate = {2025-03-20},
  abstract = {This paper proposes an extension of the class of plural expressions, a generalized analysis of the denotations of such expressions and a novel account of how they semantically combine with other elements in the sentence. The point of departure is the observation that definite plural DPs and and-coordinations with coordinates of several semantic categories share certain features --- in particular cumulativity---in the context of other plural expressions. Existing analyses of conjunction fail to derive these parallels and I propose that and-coordinations should be analyzed as denoting pluralities (of whatever kind of semantic object their conjuncts denote). This, in turn, raises the question of how pluralities combine with other material in the sentence. I show that a simple expansion of the standard analysis thereof, which puts the workload onto the predicate, is insufficient. I propose an alternative which is based on the idea that all semantic domains contain pluralities and involves plural projection. In this system, the truth-conditions of sentences containing plurality-denoting expressions are not due to the semantic expansion of the predicate (as in existing analyses), but the result of a step-by-step process: Once a plurality enters the derivation, the node immediately dominating it will also denote a plurality, namely of the values obtained by a particular combination of the plurality and the denotation of its sister. BibTeX info},
  copyright = {Copyright (c) 2019 Viola Schmitt},
  langid = {english},
  keywords = {conjunction,cross-categorial operations,cumulative composition,cumulativity,plurality},
  file = {/home/matthieu/Zotero/storage/Y9TUVJ8L/Schmitt - 2019 - Pluralities across categories and plural projectio.pdf}
}

@incollection{selingerSurveyGraphicalLanguages2010,
  title = {A Survey of Graphical Languages for Monoidal Categories},
  author = {Selinger, Peter},
  year = {2010},
  volume = {813},
  eprint = {0908.3347},
  primaryclass = {math},
  pages = {289--355},
  doi = {10.1007/978-3-642-12821-9_4},
  urldate = {2025-04-03},
  abstract = {This article is intended as a reference guide to various notions of monoidal categories and their associated string diagrams. It is hoped that this will be useful not just to mathematicians, but also to physicists, computer scientists, and others who use diagrammatic reasoning. We have opted for a somewhat informal treatment of topological notions, and have omitted most proofs. Nevertheless, the exposition is sufficiently detailed to make it clear what is presently known, and to serve as a starting place for more in-depth study. Where possible, we provide pointers to more rigorous treatments in the literature. Where we include results that have only been proved in special cases, we indicate this in the form of caveats.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Category Theory},
  file = {/home/matthieu/Zotero/storage/8F853CTA/Selinger - 2010 - A survey of graphical languages for monoidal categ.pdf;/home/matthieu/Zotero/storage/5683YCG6/0908.html}
}

@book{SemanticsTheories2019,
  title = {Semantics - {{Theories}}},
  year = {2019},
  month = feb,
  publisher = {De Gruyter Mouton},
  doi = {10.1515/9783110589245},
  urldate = {2025-03-19},
  abstract = {Now in paperback for the first time since its original publication, the material gathered here is perfect for anyone who needs a detailed and accessible introduction to the important semantic theories. Designed for a wide audience, it will be of great value to linguists, cognitive scientists, philosophers, and computer scientists working on natural language. The book covers theories of lexical semantics, cognitively oriented approaches to semantics, compositional theories of sentence semantics, and discourse semantics. This clear, elegant explanation of the key theories in semantics research is essential reading for anyone working in the area.},
  copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
  isbn = {978-3-11-058924-5},
  langid = {english},
  keywords = {Generative and Cognitive Linguistics,Linguistic Theories,Semantics},
  file = {/home/matthieu/Zotero/storage/8B2STNQX/2019 - Semantics - Theories.pdf}
}

@inproceedings{shatnawiEquivalenceDetectionUsing2007,
  title = {Equivalence Detection Using Parse-Tree Normalization for Math Search},
  booktitle = {2007 2nd {{International Conference}} on {{Digital Information Management}}},
  author = {Shatnawi, Mohammed and Youssef, Abdou},
  year = {2007},
  month = oct,
  volume = {2},
  pages = {643--648},
  doi = {10.1109/ICDIM.2007.4444297},
  urldate = {2025-04-28},
  abstract = {In recent years, efforts have begun to put math contents on the Web. As for other types of Web information, search capabilities should be provided to enable users to find what they need because without the ability to search the data for specific items, the data is useless. Conventional (i.e. textbased or even multimedia-based) search engines fall short of providing math-search capabilities. Preliminary efforts to create math-search systems have started, and many of the issues and the challenges for building such systems have been identified. One of the more difficult challenges is the detection of mathematical equivalence between expression in users' queries and expressions in math contents. The purpose of this research is to develop techniques and algorithm for equivalence-detection based math search. In particular, this research aims to explore some proposed normalization rules, then to develop a general way that can be utilized to transform both the repository contents and users' input expressions into a unified normalized form.},
  keywords = {Computer science,Information retrieval,Search engines,Thesauri,Vocabulary},
  file = {/home/matthieu/Zotero/storage/2TVEWFMC/Shatnawi et Youssef - 2007 - Equivalence detection using parse-tree normalizati.pdf}
}

@article{siederdissenProductGrammarsAlignment2015,
  title = {Product {{Grammars}} for {{Alignment}} and {{Folding}}},
  author = {zu Siederdissen, Christian H{\"o}ner and Hofacker, Ivo L. and Stadler, Peter F.},
  year = {2015},
  month = may,
  journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
  volume = {12},
  number = {3},
  pages = {507--519},
  issn = {1557-9964},
  doi = {10.1109/TCBB.2014.2326155},
  urldate = {2025-05-06},
  abstract = {We develop a theory of algebraic operations over linear and context-free grammars that makes it possible to combine simple ``atomic'' grammars operating on single sequences into complex, multi-dimensional grammars. We demonstrate the utility of this framework by constructing the search spaces of complex alignment problems on multiple input sequences explicitly as algebraic expressions of very simple one-dimensional grammars. In particular, we provide a fully worked frameshift-aware, semiglobal DNA-protein alignment algorithm whose grammar is composed of products of small, atomic grammars. The compiler accompanying our theory makes it easy to experiment with the combination of multiple grammars and different operations. Composite grammars can be written out in LATEX for documentation and as a guide to implementation of dynamic programming algorithms. An embedding in Haskell as a domain-specific language makes the theory directly accessible to writing and using grammar products without the detour of an external compiler. Software and supplemental files available here: http://www.bioinf. uni-leipzig.de/Software/gramprod/.},
  keywords = {Bioinformatics,Computational biology,context free grammar,Dynamic programming,Haskell,Heuristic algorithms,linear grammar,multiple alignment,product structure},
  file = {/home/matthieu/Zotero/storage/DSE8DU2P/Siederdissen et al. - 2015 - Product Grammars for Alignment and Folding.pdf}
}

@book{smolenskyHarmonicMindNeural2006,
  title = {The Harmonic Mind: {{From}} Neural Computation to Optimality-Theoretic Grammar},
  shorttitle = {The Harmonic Mind},
  author = {Smolensky, Paul and Legendre, G{\'e}raldine},
  year = {2006},
  publisher = {MIT press},
  address = {Cambridge},
  isbn = {978-0-262-19528-7},
  langid = {english}
}

@inproceedings{sobocinskiCARTOGRAPHERToolString2019,
  title = {{{CARTOGRAPHER}}: {{A Tool}} for {{String Diagrammatic Reasoning}}},
  shorttitle = {{{CARTOGRAPHER}}},
  booktitle = {8th {{Conference}} on {{Algebra}} and {{Coalgebra}} in {{Computer Science}} ({{CALCO}} 2019)},
  author = {Soboci{\'n}ski, Pawe{\l} and Wilson, Paul W. and Zanasi, Fabio},
  editor = {Roggenbach, Markus and Sokolova, Ana},
  year = {2019},
  series = {Leibniz {{International Proceedings}} in {{Informatics}} ({{LIPIcs}})},
  volume = {139},
  pages = {20:1--20:7},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address = {Dagstuhl, Germany},
  issn = {1868-8969},
  doi = {10.4230/LIPIcs.CALCO.2019.20},
  urldate = {2025-04-07},
  isbn = {978-3-95977-120-7},
  keywords = {graphical reasoning,string diagram,symmetric monoidal category,tool},
  file = {/home/matthieu/Zotero/storage/LKE6XHHW/Sobociński et al. - 2019 - CARTOGRAPHER A Tool for String Diagrammatic Reaso.pdf}
}

@article{swartSemanticsPragmaticsPlurals2010,
  title = {The Semantics and Pragmatics of Plurals},
  author = {de Swart, Henri{\"e}tte and Farkas, Donka},
  year = {2010},
  month = mar,
  journal = {Semantics and Pragmatics},
  volume = {3},
  pages = {6:1-54},
  issn = {1937-8912},
  doi = {10.3765/sp.3.6},
  urldate = {2025-03-20},
  abstract = {This paper addresses the semantics and pragmatics of singular and plural nominals in languages that manifest a binary morphological number distinction within this category. We review the main challenges such an account has to meet, and develop an analysis which treats the plural morpheme as semantically relevant, and the singular form as not contributing any number restriction on its own but acquiring one when in competition with the plural form. The competition between singular and plural nominals is grounded in bidirectional optimization over form-meaning pairs. The main conceptual advantage our proposal has over recent alternative accounts is that it respects Horn's 'division of pragmatic labor', in that it treats morphologically marked forms as semantically marked, and morphologically unmarked forms as semantically unmarked. In our account, plural forms are polysemous between an exclusive plural sense, which enforces sum reference, and an inclusive sense, which allows both atoms and sums as possible witnesses. The analysis predicts that a plural form is pragmatically appropriate only in case sum values are among the intended referents. To account for the choice between these two senses in context we invoke the Strongest Meaning Hypothesis, an independently motivated pragmatic principle. Finally, we show how the approach we develop explains some puzzling contrasts in number marking between English "three/more children" and Hungarian "h{\'a}rom/t{\"o}bb gyerek" ('three/more child'), a problem that has not been properly accounted for in the literature so far. doi:10.3765/sp.3.6 BibTeX info},
  copyright = {Copyright (c) 2014 Henri{\"e}tte de Swart, Donka Farkas},
  langid = {english},
  keywords = {Hungarian,markedness,morphology,optimality theory,plural,pragmatics,semantics,singular,strongest meaning hypothesis},
  file = {/home/matthieu/Zotero/storage/2RLFMCTV/Swart et Farkas - 2010 - The semantics and pragmatics of plurals.pdf}
}

@article{swierstraDataTypesCarte2008,
  title = {Data Types {\`a} La Carte},
  author = {Swierstra, Wouter},
  year = {2008},
  month = jul,
  journal = {Journal of Functional Programming},
  volume = {18},
  number = {4},
  pages = {423--436},
  issn = {1469-7653, 0956-7968},
  doi = {10.1017/S0956796808006758},
  urldate = {2025-03-27},
  abstract = {This paper describes a technique for assembling both data types and functions from isolated individual components. We also explore how the same technology can be used to combine free monads and, as a result, structure Haskell's monolithic IO monad.},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/WHA9BIFJ/Swierstra - 2008 - Data types à la carte.pdf}
}

@article{vandenbergFrameworkHigherorderEffects2024,
  title = {A Framework for Higher-Order Effects \& Handlers},
  author = {{van den Berg}, Birthe and Schrijvers, Tom},
  year = {2024},
  month = may,
  journal = {Science of Computer Programming},
  volume = {234},
  pages = {103086},
  issn = {0167-6423},
  doi = {10.1016/j.scico.2024.103086},
  urldate = {2025-03-27},
  abstract = {Algebraic effects \& handlers are a modular approach for modeling side-effects in functional programming. Their syntax is defined in terms of a signature of effectful operations, encoded as a functor, that are plugged into the free monad; their denotational semantics is defined by fold-style handlers that only interpret their part of the syntax and forward the rest. However, not all effects are algebraic: some need to access an internal computation. For example, scoped effects distinguish between a computation in scope and out of scope; parallel effects parallelize over a computation, latent effects defer a computation. Separate definitions have been proposed for these higher-order effects and their corresponding handlers, often leading to expedient and complex monad definitions. In this work we propose a generic framework for higher-order effects, generalizing algebraic effects \& handlers: a generic free monad with higher-order effect signatures and a corresponding interpreter. Specializing this higher-order syntax leads to various definitions of previously defined (scoped, parallel, latent) and novel (writer, bracketing) effects. Furthermore, we formally show our framework theoretically correct, also putting different effect instances on formal footing; a significant contribution for parallel, latent, writer and bracketing effects.},
  keywords = {Algebraic effects and handlers,Datatypes a la carte,Free monad,Higher-order effects and handlers},
  file = {/home/matthieu/Zotero/storage/ANWYSW98/van den Berg et Schrijvers - 2024 - A framework for higher-order effects & handlers.pdf;/home/matthieu/Zotero/storage/RESW4VTB/S0167642324000091.html}
}

@misc{verdiereTestingGraphIsotopy2013,
  title = {Testing {{Graph Isotopy}} on {{Surfaces}}},
  author = {de Verdi{\`e}re, {\'E}ric Colin and de Mesmay, Arnaud},
  year = {2013},
  month = oct,
  number = {arXiv:1310.2745},
  eprint = {1310.2745},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1310.2745},
  urldate = {2025-03-31},
  abstract = {We investigate the following problem: Given two embeddings G\_1 and G\_2 of the same abstract graph G on an orientable surface S, decide whether G\_1 and G\_2 are isotopic; in other words, whether there exists a continuous family of embeddings between G\_1 and G\_2. We provide efficient algorithms to solve this problem in two models. In the first model, the input consists of the arrangement of G\_1 (resp., G\_2) with a fixed graph cellularly embedded on S; our algorithm is linear in the input complexity, and thus, optimal. In the second model, G\_1 and G\_2 are piecewise-linear embeddings in the plane minus a finite set of points; our algorithm runs in O(n{\textasciicircum}\{3/2\}{\textbackslash}log n) time, where n is the complexity of the input. The graph isotopy problem is a natural variation of the homotopy problem for closed curves on surfaces and on the punctured plane, for which algorithms have been given by various authors; we use some of these algorithms as a subroutine. As a by-product, we reprove the following mathematical characterization, first observed by Ladegaillerie (1984): Two graph embeddings are isotopic if and only if they are homotopic and congruent by an oriented homeomorphism.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computational Geometry,Computer Science - Data Structures and Algorithms,Mathematics - Geometric Topology},
  file = {/home/matthieu/Zotero/storage/5QGIXC76/Verdière et Mesmay - 2013 - Testing Graph Isotopy on Surfaces.pdf;/home/matthieu/Zotero/storage/5NC3TV2J/1310.html}
}

@inproceedings{wadlerTheoremsFree1989,
  title = {Theorems for Free!},
  booktitle = {Proceedings of the Fourth International Conference on {{Functional}} Programming Languages and Computer Architecture},
  author = {Wadler, Philip},
  year = {1989},
  month = nov,
  series = {{{FPCA}} '89},
  pages = {347--359},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/99370.99404},
  urldate = {2025-03-24},
  isbn = {978-0-89791-328-7},
  file = {/home/matthieu/Zotero/storage/GBVTWTMB/Wadler - 1989 - Theorems for free!.pdf}
}

@misc{wang-mascianicaDistillingTextCircuits2023,
  title = {Distilling {{Text}} into {{Circuits}}},
  author = {{Wang-Mascianica}, Vincent and Liu, Jonathon and Coecke, Bob},
  year = {2023},
  month = jan,
  number = {arXiv:2301.10595},
  eprint = {2301.10595},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2301.10595},
  urldate = {2025-04-04},
  abstract = {This paper concerns the structure of meanings within natural language. Earlier, a framework named DisCoCirc was sketched that (1) is compositional and distributional (a.k.a. vectorial); (2) applies to general text; (3) captures linguistic `connections' between meanings (cf. grammar) (4) updates word meanings as text progresses; (5) structures sentence types; (6) accommodates ambiguity. Here, we realise DisCoCirc for a substantial fragment of English. When passing to DisCoCirc's text circuits, some `grammatical bureaucracy' is eliminated, that is, DisCoCirc displays a significant degree of (7) inter- and intra-language independence. That is, e.g., independence from word-order conventions that differ across languages, and independence from choices like many short sentences vs. few long sentences. This inter-language independence means our text circuits should carry over to other languages, unlike the language-specific typings of categorial grammars. Hence, text circuits are a lean structure for the `actual substance of text', that is, the inner-workings of meanings within text across several layers of expressiveness (cf. words, sentences, text), and may capture that what is truly universal beneath grammar. The elimination of grammatical bureaucracy also explains why DisCoCirc: (8) applies beyond language, e.g. to spatial, visual and other cognitive modes. While humans could not verbally communicate in terms of text circuits, machines can. We first define a `hybrid grammar' for a fragment of English, i.e. a purpose-built, minimal grammatical formalism needed to obtain text circuits. We then detail a translation process such that all text generated by this grammar yields a text circuit. Conversely, for any text circuit obtained by freely composing the generators, there exists a text (with hybrid grammar) that gives rise to it. Hence: (9) text circuits are generative for text.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Logic in Computer Science,Mathematics - Category Theory},
  file = {/home/matthieu/Zotero/storage/FJYMMM7R/Wang-Mascianica et al. - 2023 - Distilling Text into Circuits.pdf;/home/matthieu/Zotero/storage/KYLW98F3/2301.html}
}

@phdthesis{wang-mascianicaStringDiagramsText2023,
  type = {{{http://purl.org/dc/dcmitype/Text}}},
  title = {String Diagrams for Text},
  author = {{Wang-Ma{\'s}cianica}, V.},
  year = {2023},
  urldate = {2025-04-04},
  abstract = {There are potentially practical and theoretical benefits to a fresh mathematical take on basic formal linguistics. String diagrams are formal, intuitive, expressive, fun, and pretty.},
  langid = {english},
  school = {University of Oxford},
  file = {/home/matthieu/Zotero/storage/LXQ5YTNY/Wang-Maścianica - 2023 - String diagrams for text.pdf}
}

@article{wellsTypabilityTypeChecking1999,
  title = {Typability and Type Checking in {{System F}} Are Equivalent and Undecidable},
  author = {Wells, J. B.},
  year = {1999},
  month = jun,
  journal = {Annals of Pure and Applied Logic},
  volume = {98},
  number = {1},
  pages = {111--156},
  issn = {0168-0072},
  doi = {10.1016/S0168-0072(98)00047-5},
  urldate = {2025-03-11},
  abstract = {Girard and Reynolds independently invented System F (a.k.a. the second-order polymorphically typed lambda calculus) to handle problems in logic and computer programming language design, respectively. Viewing F in the Curry style, which associates types with untyped lambda terms, raises the questions of typability and type checking. Typability asks for a term whether there exists some type it can be given. Type checking asks, for a particular term and type, whether the term can be given that type. The decidability of these problems has been settled for restrictions and extensions of F and related systems and complexity lower-bounds have been determined for typability in F, but this report is the first to resolve whether these problems are decidable for System F. This report proves that type checking in F is undecidable, by a reduction from semi-unification, and that typability in F is undecidable, by a reduction from type checking. Because there is an easy reduction from typability to type checking, the two problems are equivalent. The reduction from type checking to typability uses a novel method of constructing lambda terms that simulate arbitrarily chosen type environments. All of the results also hold for the {$\lambda$}I-calculus.},
  keywords = {Lambda calculus,Semi-unification,System F,Typability,Type checking,Type inference},
  file = {/home/matthieu/Zotero/storage/2THFKMCM/S0168007298000475.html}
}

@misc{wilsonDataParallelAlgorithmsString2023,
  title = {Data-{{Parallel Algorithms}} for {{String Diagrams}}},
  author = {Wilson, Paul and Zanasi, Fabio},
  year = {2023},
  month = may,
  number = {arXiv:2305.01041},
  eprint = {2305.01041},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.01041},
  urldate = {2025-04-04},
  abstract = {We give parallel algorithms for string diagrams represented as structured cospans of ACSets. Specifically, we give linear (sequential) and logarithmic (parallel) time algorithms for composition, tensor product, construction of diagrams from arbitrary \${\textbackslash}Sigma\$-terms, and application of functors to diagrams. Our datastructure can represent morphisms of both the free symmetric monoidal category over an arbitrary signature as well as those with a chosen Special Frobenius structure. We show how this additional (hypergraph) structure can be used to map diagrams to diagrams of optics. This leads to a case study in which we define an algorithm for efficiently computing symbolic representations of gradient-based learners based on reverse derivatives. The work we present here is intended to be useful as a general purpose datastructure. Implementation requires only integer arrays and well-known algorithms, and is data-parallel by constuction. We therefore expect it to be applicable to a wide variety of settings, including embedded and parallel hardware and low-level languages.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Programming Languages,Mathematics - Category Theory},
  file = {/home/matthieu/Zotero/storage/M4KJ894E/Wilson et Zanasi - 2023 - Data-Parallel Algorithms for String Diagrams.pdf;/home/matthieu/Zotero/storage/KM2WZNFJ/2305.html}
}

@article{wilsonStringDiagramsStrictification2024,
  title = {String Diagrams for {{Strictification}} and {{Coherence}}},
  author = {Wilson, Paul and Ghica, Dan and Zanasi, Fabio},
  year = {2024},
  month = oct,
  journal = {Logical Methods in Computer Science},
  volume = {Volume 20, Issue 4},
  pages = {13982},
  issn = {1860-5974},
  doi = {10.46298/lmcs-20(4:8)2024},
  urldate = {2025-04-04},
  abstract = {Whereas string diagrams for strict monoidal categories are well understood, and have found application in several fields of Computer Science, graphical formalisms for non-strict monoidal categories are far less studied. In this paper, we provide a presentation by generators and relations of string diagrams for non-strict monoidal categories, and show how this construction can handle applications in domains such as digital circuits and programming languages. We prove the correctness of our construction, which yields a novel proof of Mac Lane's strictness theorem. This in turn leads to an elementary graphical proof of Mac Lane's coherence theorem, and in particular allows for the inductive construction of the canonical isomorphisms in a monoidal category.},
  langid = {english},
  file = {/home/matthieu/Zotero/storage/QBC4WHBA/Wilson et al. - 2024 - String diagrams for Strictification and Coherence.pdf}
}

@inproceedings{wuEffectHandlersScope2014,
  title = {Effect Handlers in Scope},
  booktitle = {Proceedings of the 2014 {{ACM SIGPLAN}} Symposium on {{Haskell}}},
  author = {Wu, Nicolas and Schrijvers, Tom and Hinze, Ralf},
  year = {2014},
  month = sep,
  series = {Haskell '14},
  pages = {1--12},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2633357.2633358},
  urldate = {2025-03-27},
  abstract = {Algebraic effect handlers are a powerful means for describing effectful computations. They provide a lightweight and orthogonal technique to define and compose the syntax and semantics of different effects. The semantics is captured by handlers, which are functions that transform syntax trees.Unfortunately, the approach does not support syntax for scoping constructs, which arise in a number of scenarios. While handlers can be used to provide a limited form of scope, we demonstrate that this approach constrains the possible interactions of effects and rules out some desired semantics.This paper presents two different ways to capture scoped constructs in syntax, and shows how to achieve different semantics by reordering handlers. The first approach expresses scopes using the existing algebraic handlers framework, but has some limitations. The problem is fully solved in the second approach where we introduce higher-order syntax.},
  isbn = {978-1-4503-3041-1},
  file = {/home/matthieu/Zotero/storage/H5YL93HH/Wu et al. - 2014 - Effect handlers in scope.pdf}
}
