\documentclass[math, english, info]{beamercours}
\makeatletter
\def\tikzimp@rt{1}
\makeatother

\bibliography{slides.bib}

\input{aux/preamble}

\title{Effect-Driven Parsing}
\subtitle{Formal studies on a categorical approach to semantic parsing}
\institute{École Normale Supérieure | Yale University}
\addlogo{~/DEV/latex/source/ens_psl.pdf}

\begin{document}
\maketitle

\section{Introduction and a teeny tiny bit of math}
\subsection{General Introduction}
\begin{frame}
	\frametitle{General Introduction}
	This work, based on \cite{bumfordEffectdrivenInterpretationFunctors2025} aims
	to provide a categorical formalization of a type and effects system for
	semantic interpretation of the natural language.

	\medskip

	We will develop a graphical formalism for semantic type-driven parsing that
	explains how to derive the meaning of a sentence from the meaning of its
	words.
\end{frame}

\begin{frame}[fragile]
	\frametitle{Types in Semantics of Natural Languages}
	\setcellgapes{3pt}
	\makegapedcells
	\begin{NiceTabular}{>{\bf}LLL}
		Expression & \rm Type & \lambda\text{-Term} \\
		\word{planet}{\e\to\t}{\lambda x. \w{planet} x}{common nouns}
		\word{carnivorous}{\left( \e \to \t \right)}{\lambda x. \w{carnivorous}x}{predicative adjectives}
		\word{skillful}{\left( \e \to \t \right) \to \left( \e \to \t \right)}{\lambda p. \lambda x. px \land \w{skillful} x}{predicate modifier adjectives}
		\word{Jupiter}{\e}{{\bf j}\in \Var}{proper nouns}
		\word{sleep}{\e \to \t}{\lambda x. \w{sleep} x}{intransitive verbs}
		\CodeAfter
		\begin{tikzpicture}
			\draw[double] (1|-2) -- (4|-2);
			\foreach \r in {4,6,...,10} {\draw (1|-\r) -- (4|-\r);}
		\end{tikzpicture}
	\end{NiceTabular}
\end{frame}

\begin{frame}[fragile]
	\frametitle{Handling Non-Determinism}
	What should be the type of expressions such as \textbf{a cat} or \textbf{Jupiter, a planet}?
	\pause

	\smallskip

	Since we should be able to use \textbf{a cat} and \textbf{the cat} interexchangebly - from a syntax point of view - they should have the same type.
	We use \emph{effects} to do the difference between:
	\begin{equation*}
		\w{a\ cat} = \{c \mid \w{cat} c\}
	\end{equation*}
	\begin{equation*}
		\w{the\ cat} = x \text{ if } \mathbf{cat}^{-1}(\top) = \{x\} \text{ else } \#
	\end{equation*}
\end{frame}

\subsection{Computer Basis}
\begin{frame}[fragile]
	\frametitle{Side-Effects}
	\begin{center}
		\begin{minipage}[b]{.45\textwidth}
			\begin{code}{python}
				def add(x, y):
				return x + y
			\end{code}
			\centering
			A pure program.
		\end{minipage}
		\begin{minipage}[b]{.45\textwidth}
			\begin{code}{python}
				def add(x, y):
				print("I LOVE CHOMSKY")
				return x + y
			\end{code}
			\centering
			An impure program
		\end{minipage}
	\end{center}
	\pause
	The addition of the \texttt{print} statement modifies the behaviour of the
	programs: we do not know what actually happens to the memory state of the
	computer.

	This is called a side effect, or simply effect.
\end{frame}

\begin{frame}
	\frametitle{Category Theory 101}
	\begin{itemize}
		\item A category $\mC$ is a structure with things called objects, and
		      ways to go between things called morphisms or arrows.
		      \pause
		\item Objects represent the set of objects of a certain type and arrows
		      represent ways to go from one type to another language.
		      The type of a function is then an object that represents the set
		      of arrows between $A \to B$.
	\end{itemize}
\end{frame}

\begin{frame}[fragile]
	\frametitle{Category Theory 10201}
	\begin{itemize}
		\item A functor from a category to another is a morphism between
		      categories.
		      It translates types as well as function between types.
		      \pause
		      \begin{category}
			      A\ar[r, "\phi"]\ar[d, "F"'] & B\ar[d, "F"] \\
			      FA\ar[r, "F\phi"'] & FB
		      \end{category}
		      Functors represent modifications of a type: they represent effects.
	\end{itemize}
\end{frame}

\begin{frame}[fragile]
	\frametitle{Category Theory 10202}
	\begin{itemize}
		\item A natural transformation is a morphism from a functor to another.
		      \pause
		      \begin{category}
			      FA\ar[r, "\theta_{A}"]\ar[d, "F\phi"'] & GA\ar[d, "G\phi"]\\
			      FB\ar[r, "\theta_{B}"'] & GB
		      \end{category}
	\end{itemize}
\end{frame}

\begin{frame}[fragile]
	\frametitle{Category of Endofunctors}
	\begin{itemize}
		\item A monadic effect is a type of effect that can be created from an
		      object, without losing information.
		\item When an object bears two of the same monadic effect, it can be
		      transformed to only bear one instance of the effect.
	\end{itemize}
	\pause

	Mathematically, we have two natural transformations $\eta: \Id \Rightarrow M$
	and $\mu: MM \Rightarrow M$ called unit and multiplication or join.
\end{frame}

\begin{frame}[fragile]
	\frametitle{I'm FREE! Forget it.}
	An adjunction between two functors $L \dashv R$ is a pair of natural
	transformations $\eta: \Id \Rightarrow L \circ R$ and $\epsilon: R \circ L
		\Rightarrow \Id$.

	\smallskip

	It mimics the behaviour of a bijection for functor composition.

	\pause

	A classical example is the Read - Write adjunction.
	It mimics the behaviour of the anaphora: once we have wrote data next to a
	denotation, reading said data makes us go back to the beginning, or almost.
\end{frame}

\section{Implementing the Category-Theoretical Type System}
\subsection{Presenting the Type System}

\begin{frame}
	\frametitle{A Type and Effect System}
	Let $\mL$ be our language (more on that later).
	We only suppose that our words can be applied to one another in their
	denotation system.

	\pause

	Let $\mC$ be a cartesian closed category used for typing the lexicon.
	Let $\mathcal{F}(\mL)$ be a set of functors used for representing the words
	that add an effect to our language.

	\pause\smallskip

	We consider $\bar{\mC}$ the categorical closure of $\mC$ under the action
	of $\mathcal{F}(\mL)^{*}$.
	We close it for the cartesian product and exponential of $\mC$.

	$\bar{\mC}$ represents all possible combinations of a sequence of effects
	and a base type, contains functions and products.
\end{frame}

\begin{frame}[fragile]
	\frametitle{Typing Rules}
	\only<1-2>{We then have typing judgements for basic combinations:
		\begin{align*}
			\only<1>{
			\frac{\cont x: \tau \poulpe \cont F \in \mathcal{F}(\mL)}{\cont Fx: F\tau }\fracnotate{Cons}                                          \\[.25cm]
			\frac{\cont x: F\tau_{1} \poulpe \cont \phi: \tau_{1} \to \tau_{2}}{\cont \phi x: F\tau_{2} }\fracnotate{\texttt{fmap}}               \\[.25cm]
				\frac{\cont x: \tau_{1} \poulpe \cont \phi: \tau_{1} \to \tau_{2}}{\cont \phi x: \tau_{2}}\fracnotate{App}
			}
			\only<2>{
			\frac{\cont x: A\tau_{1} \poulpe \cont \phi: A\left( \tau_{1} \to \tau_{2} \right)}{\cont \phi x: A\tau_{2}}\fracnotate{\texttt{<*>}} \\[.25cm]
			}
		\end{align*}
	}
	\only<3>{Typing judgements for natural transformations:
		\begin{align*}
			\frac{\cont x: \tau}{\cont x: A\tau}\fracnotate{\texttt{pure/return}} \\[.25cm]
			\frac{\cont x: MM\tau}{\cont x: M\tau}\fracnotate{\texttt{>>=}}
		\end{align*}
		More generally:
		\begin{align*}
			\forall F \overset{\theta}{\Longrightarrow} G,\poulpe \frac{\cont x: F\tau \poulpe \cont G: S' \subseteq \star \poulpe \tau \in S'}{\cont x : G\tau}\fracnotate{\texttt{nat}}
		\end{align*}
		To ensure termination and decidability, we prevent the use of the unit rule
		out of the blue, more on why that is fine later.
	}
\end{frame}

\subsection{Presenting a Language}

\begin{frame}
	\frametitle{Language}
	To present the language, we of course need the syntax of the language, as
	well as an increased model of our lexicon.
\end{frame}

\begin{frame}[fragile]
	\frametitle{Lexicon}
	\resizebox{\textwidth}{!}{
		\setcellgapes{3pt}
		\makegapedcells
		\begin{NiceTabular}{>{\bf}LLL}
			Expression & \rm Type & \lambda\text{-Term} \\
			\word{it}{\f{G}\e}{\lambda g. g_{0}}{}
			\word{\cdot\w{, a} \cdot}{\e \to \left(\e \to \t\right) \to \f{W}\e}{\lambda x. \lambda p. \scalar{x, p x}}{}
			\word{which}{\left( \e \to \t \right)\to \f{S}\e}{\lambda p. \left\{x \suchthat px\right\}}{}
			\word{the}{\left( \e \to \t \right) \to \f{M}\e}{\lambda p. x \text{ if } p^{-1}\left( \top \right) = \{x\} \text{ else } \#}{}
			\word{a}{\left( \e \to \t \right) \to \f{D}\e}{\lambda p. \lambda s. \left\{ \scalar{x, x \ppl s}\suchthat p x\right\}}{}
			\word{every}{\left( \e \to \t \right)\to \f{C}\e}{\lambda p. \lambda c. \forall x, px \Rightarrow cx}{}
			\CodeAfter
			\begin{tikzpicture}
				\draw[double] (1|-2) -- (4|-2);
				\foreach \r in {3,...,8} {\draw (1|-\r) -- (4|-\r);}
			\end{tikzpicture}
		\end{NiceTabular}
	}
\end{frame}

\begin{frame}
	\frametitle{Higher-Order Constructs}
	\only<1-2>{Using the notion of functors, we can also implement higher-order semantic
		constructions in our lexicon, such as the future, without caring about
		morphological markers:}
	\only<2>{%
		\begin{equation*}
			\columneqs{
				\bf future\left(be\left( I, a\ cat \right)\right)
				\xrightarrow{\beta} be\left( future\left( I \right), a\ cat \right)
				\xrightarrow{\beta} be\left( future\left( I \right), a\ cat \right)
			}
		\end{equation*}
		Those constructs are integrated by using natural transformations explaining
		their propagation through other effects, as those are purely
		semantic predicates.
	}
	\only<3>{
		For the plural, this gives:
		\resizebox{\textwidth}{!}{%
			\def\arraystretch{1.3}
			\setcellgapes{3pt}
			\makegapedcells
			\begin{NiceTabular}{>{\bf}c>{\cont}C>{\Pi(p) = }L}
				CN(P)                       & p: \left(\e \to \t\right)                                & \lambda x.\left( px \land \abs{x} \geq 2 \right)                                                \\
				\multirow{2}{*}{\bf ADJ(P)} & p: \left( \e \to \t \right)                              & \lambda x. \left( px \land \abs{x} \geq 2 \right)                                               \\
				                            & p: \left( \e \to \t \right) \to \left( \e \to \t \right) & \lambda \nu. \lambda x. \left( p\left( \nu \right)\left( x \right) \land \abs{x} \geq 2 \right) \\
				\multirow{2}{*}{\bf NP}     & p: \e                                                    & p                                                                                               \\
				                            & p: \left( \e \to \t \right) \to \t                       & \lambda \nu. p\left( \Pi \nu \right)                                                            \\
				IV(P)/VP                    & p: \e \to \t                                             & \lambda o. \left( po \land \abs{x} \geq 2 \right)                                               \\
				TV(P)                       & p: \e \to \e \to \t                                      & \lambda s. \lambda o. \left( p\left( s \right)\left( o \right) \land \abs{s} \geq 2 \right)     \\
				\CodeAfter
				\begin{tikzpicture}
					\foreach \r in {2,...,7} {\draw[dashed] ($(2|-\r) + (.1, 0)$) -- (4|-\r);}
					\foreach \r in {2, 4, 6, 7} {\draw (1|-\r) -- (4|-\r);}
				\end{tikzpicture}
			\end{NiceTabular}
		}
	}
\end{frame}

\section{Effect Handling}
\subsection{What is a chair ?}
\begin{frame}
	\frametitle{Handlers}
	A handler for an effect $F$ is a natural transformation $F \Rightarrow \Id$.

	\smallskip

	Handlers should also be exact inverses to monadic and applicative units:
	this justifies semantically why we can remove the usage of the unit rule out
	of certain situations.
\end{frame}


\begin{frame}
	\frametitle{Intrinsic and Speaker-Defined Handlers}
	There are two main types of handlers that are of interest to us:
	\pause
	\begin{enumerate}
		\item Language-Defined Handlers, which are defined with
		      adjunctions and comonads, for example.
		      Those arise from fundamental properties of the considered effects.
		      \pause
		\item Speaker-dependant handlers, which are considered when
		      retrieving the denotation from a sentence from under the effects
		      that arose in the computation of its meaning.
		      Those need to be considered dependent on the speaker because for
		      example of the multiple ways to solve non-determinism.
	\end{enumerate}
\end{frame}

\subsection{The ropes of effect handling.}
\begin{frame}[allowframebreaks]
	\frametitle{String Diagrams in Denotations}
	A string diagram is a representation of the side-effects and types of a
	sentence across its computation.

	\smallskip

	The lines are functors (effects or base types), the nodes are natural
	transformations.

	\begin{center}
		\hfill
		\inputtikz{sd-thecatsleeps}
		\hfill
		\begin{minipage}[b]{.4\textwidth}
			This diagram for example represents the sentence \textsl{The cat sleeps}.
			The order of the words and position of the strings will be explained in
			detail in the next section.
		\end{minipage}
		\hfill
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{String Diagram Equivalence}
	String diagrams will be the formalism we use to compute equality between
	denotations, and especially handling the denotations.
	\begin{thm}[Theorem 3.1 \cite{selingerSurveyGraphicalLanguages2010}, Theorem 1.2 \cite{joyalGeometryTensorCalculus1991}]
		\label{thm:isotopy}
		A well-formed equation between morphism terms in the language of monoidal
		categories follows from the axioms of monoidal categories if and only if it
		holds, up to planar isotopy, in the graphical language.
	\end{thm}
\end{frame}

\subsection{Severing the ties.}
\begin{frame}[allowframebreaks]
	\frametitle{Conversion Software, version 7.0.}
	Every property of the functors, monads, natural transformations, adjunctions
	and more can be explained in terms of commutative diagrams, but also as
	string diagrams.

	First, the elevator equations are a consequence of \ref{thm:isotopy}:
	\begin{equation}
		\resizebox{.8\textwidth}{!}{\inputtikz{sd-elevator}}
		\label{eq:elevator}
		\tag{\href{https://î.fr/ascenseurs}{\emoji{elevator}}}
	\end{equation}

	The Snake equations are a rewriting of the properties of an adjunction:
	\begin{equation}
		\resizebox{.5\textwidth}{!}{\inputtikz{sd-snake1}}
		\tag{\rotatebox[origin=c]{90}{\emoji{snake}}}
		\label{eq:snek1}
	\end{equation}

	The Monadic equations are a rewriting of the properties of a monad:
	\begin{equation}
		\resizebox{.5\textwidth}{!}{\inputtikz{sd-monad-mult}}
		\label{eq:muax}
		\tag{$\mu$}
	\end{equation}

\end{frame}

\begin{frame}[allowframebreaks]
	\frametitle{Bubba Gump Shrimps}
	\begin{thm}[Confluence]\label{thm:confluence}
		Our reduction system is confluent and therefore defines normal forms:
		\begin{enumerate}
			\item Right reductions are confluent and therefore define \emph{right} normal forms for
			      diagrams under the equivalence relation induced by exchange.
			\item Equational reductions are confluent and therefore define \emph{equational}
			      normal forms for diagrams under the equivalence relation induced by exchange.
		\end{enumerate}
	\end{thm}

	\smallskip

	\begin{thm}[Normalization Complexity]
		\label{thm:normalize}
		Reducing a diagram to its normal form is done in quadratic time in
		the number of natural transformations in it.
	\end{thm}
	This is accomplished using a formalism based on \cite{delpeuchNormalizationPlanarString2022}.
\end{frame}

\section{Semantic Parsing}

\begin{frame}
	\frametitle{String Diagram Combination}
	Given our grammar, we could build parsing trees, but that would blur the actual usefulness of our grammar and our string diagrammatic representation of sentences.

	\medskip

	We thus consider diagrams whose $1$-cells are objects in $\bar{\mC}$, i.e. types and effects and whose natural transformations are the combinators of our grammar.
\end{frame}


\section*{Bibliography}

\begin{frame}[allowframebreaks]
	\frametitle{Bibliography}
	\printbibliography{}
\end{frame}


\end{document}

