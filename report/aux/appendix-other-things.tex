\section{Other Considered Things}
\subsection{Typing with a products Category (and a bit of polymorphism)}
\label{app:prodcat}
Another way to start would be to consider product categories: one for the main
type system and one for the effects.
Let $\mC_{0}$ be a closed cartesian category representing our main type system.
Here we again consider constants and full computations as functions
$\bot \to \tau$ or $\tau \in \mathrm{Obj}\left( \mC_{0} \right)$.
Now, to type functions and functors, we need to consider a second category:
We consider $\mC_{1}$ the category representing the free monoid on
$\mF\left( \mL \right)$.
Monads and Applicatives will generate relations in that monoid.
To ease notation we will denote \emph{functor types} in $\mC_{1}$ as lists
written with head on the left.

Finally, let $\mC = \mC_{0} \times \mC_{1}$ be the product category.
This will be our typing category.
This means that the real type of objects will be
$\left( \bot \to \tau, [] \right)$, which we will still denote by $\tau$.
We will denote by $F_{n} \cdots F_{0} \tau$ the type of an object, as if it
were a composition of functions.

In that paradigm, functors simply append to the head of the \emph{functor type}
while functions will take a polymorphic form:
$x: L\tau_{1} \mapsto \phi x: L\tau_{2}$ and $\phi$'s type can be written as
$\star\tau_{1} \to \star\tau_{2}$.

\subsection{Multiple Ways}
\label{app:arities-and-denots}
In this section we will discuss what can happen when the denotation system
we consider is not actually based on a compositional model, or is independent
of the syntactic model.
In that case, our model of using typing to retrieve parsing trees will need
modifications to be integrated.

In the case where the compositional aspects of the sentence are blurred by a
non-binary arity, whether it's variable (leading to non-binary trees) or simply
non-compositional and makes use of all the words of the sentence (or the ones
prior to the last one read, like in a LLM), we can make use of higher arity
base combinators.
We replace the function application by the combinator adapted to our model,
then a theoretical (or learned) analysis of the concepts that can be modeled
by adding effects can still be done, and our work can be completed in the way
described above.

Of course in the case where no syntactic structure is used for semantics,
using semantics to derive syntax is useless, but the formalism of string
diagrams used to present the actual parsing can still be useful:
it could also be used to model the attention patterns (as side-effects of the
reading of a new token and adding its meaning to the current representation
of the sentence).
This is an insight of how to implement our enhancement onto a non-compositional
system, although that of course removes a bit of the interest of the system, as
typing will not matter in that case.

\subsection{Coproduct Integration}
In this section based on the work by
\cite{marcollimatildeetchomskynoametberwickrobertc.MathematicalStructureSyntactic}
and \cite{senturiaAlgebraicStructureMorphosyntax2025},
we explore the integration of our notion inside the structure of syntactic
merge, and why the two formalisms are compatible.
The idea behind that structure is to see the union of trees as a product and
the merging of trees as based on a coproduct in a well-defined Hopf algebra.
Now of course, with our insights on syntactico-semantic parsing, we can either
think of our parsing structure labeled by multiple modes, as in
\cite{bumfordEffectdrivenInterpretationFunctors2025}, or think of it as string
diagrams, as presented above.
In both cases, we make a more or less implicit use of the merge operation.

\medskip

Labeled trees can be seen as computed from a sequence of labeled merge.
As such, it is easy to see how one can adapt the construction of a purely
syntactic merge onto a semantic merge, using a similar approach.
There is just the need for a coloured operad to create a series of labeled
merges, like proposed in
\cite{melliesCategoricalContoursChomskySchutzenberger2025} for example.
Since there is a one-to-one mapping from our string diagrams to parse trees,
mapping explained when comparing the tables for denotations of combinators
in Figure \ref{fig:combinator-denotations} and Figure 12 in
\cite{bumfordEffectdrivenInterpretationFunctors2025}, or by looking at the
parse trees equivalent to string diagrams in Figures \ref{fig:parsing-diagram},
\ref{fig:parsing-diagram2} and \ref{fig:3dparsing-diagram}, it is easy to see
that indeed, there is a notion of merge inside our diagrams that can in a way
be expressed through a Hopf algebra, by transporting the diagrams to and from
their equivalent parsing diagram.
More generally, what this means is that a merge, in our string diagrams, is
the addition of a combinator to one, two\footnote{Or more, see
	\ref{app:arities-and-denots}} without conditions.
This is useful as a definition, because it allows integration of our system in
a broader framework, including for example the notion of morphosyntactic trees.

\medskip

However, this is not fully satisfying: like for syntax trees, applying a random
sequence of merges to a set of input strings will not always yield a properly
typed denotation.
Since type soundness is the main feature of our system, it seems weird to have
a definition of merge which cannot take that into account.

